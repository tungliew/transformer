{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7418f483",
   "metadata": {},
   "source": [
    "# Part 1: Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827da41a",
   "metadata": {},
   "source": [
    "### 逐步实验transformer\n",
    "#### 从【Inference】部分开始对模型内容进行逐步实验\n",
    "#### 首先计算memory\n",
    "#### 即encoder最后的输出结果\n",
    "#### 实验 memory = test_model.encode(src, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5165bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型结构定义，用于参照\n",
    "import copy\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h=8,d_model=512)\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=2048)\n",
    "    position = PositionalEncoding(d_model=512, dropout=0.1)\n",
    "    \n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab),\n",
    "    )\n",
    "    \n",
    "    # 作用随后补充\n",
    "    # Initialize parameters with Glorot / fan_avg\n",
    "    # 参考论文: https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26c5a20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n大致流程说明\\n1. 先实现 memory = test_model.encode(src, src_mask)，其中memory就是模型encoder输出的结果\\n\\n2. class EncoderDecoder给出encode实现如下:\\ndef encode(self, src, src_mask):\\n        return self.encoder(self.src_embed(src), src_mask)\\n\\n    2.1 首先对输入src进行Embedding\\n    src_embed = nn.Sequential(Embeddings(d_model, src_vocab), c(position))\\n    就是先对src进行Embedding,\\n    然后再对Embedding的输出进行位置编码 position = PositionalEncoding(d_model=512, dropout=0.1)\\n    \\n    2.2 对2.1的输出进行encoder\\n    其中encoder = Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N=6)\\n\\n    参看Encoder类的实现，其实就是N个EncoderLayer的堆叠，把2.1中的输出经过N个EncoderLayer最后进行norm\\n    \\n    2.3 EncoderLayer类的实现:\\n    分成2个部分: attention部分和feed_forward部分\\n    \\n        2.3.1 MultiHeadedAttention的实现\\n        norm(x) -> MultiHeadedAttention(x,x,x,mask) -> dropout -> +x [残差连接]\\n        \\n        2.3.2 feedforward类\\n        norm(x) -> PositionwiseFeedForward(x) -> dropout -> +x [残差连接]\\n        \\n        \\n        可以看出MultiHeadedAttention和feedforward结构类似，除了第二步使用的layer不一样，上述结构都通过\\n        辅助类 SublayerConnection实现\\n        \\n        需要注意的地方:\\n        在EncoderLayer的MultiHeadedAttention中,由于所有q, k, v都是来自src_emb, 所以q = k = v = x\\n        \\n        DecoderLayer的MultiHeadedAttention的区别后续补充\\n    \\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "大致流程说明\n",
    "1. 先实现 memory = test_model.encode(src, src_mask)，其中memory就是模型encoder输出的结果\n",
    "\n",
    "2. class EncoderDecoder给出encode实现如下:\n",
    "def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    2.1 首先对输入src进行Embedding\n",
    "    src_embed = nn.Sequential(Embeddings(d_model, src_vocab), c(position))\n",
    "    就是先对src进行Embedding,\n",
    "    然后再对Embedding的输出进行位置编码 position = PositionalEncoding(d_model=512, dropout=0.1)\n",
    "    \n",
    "    2.2 对2.1的输出进行encoder\n",
    "    其中encoder = Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N=6)\n",
    "\n",
    "    参看Encoder类的实现，其实就是N个EncoderLayer的堆叠，把2.1中的输出经过N个EncoderLayer最后进行norm\n",
    "    \n",
    "    2.3 EncoderLayer类的实现:\n",
    "    分成2个部分: attention部分和feed_forward部分\n",
    "    \n",
    "        2.3.1 MultiHeadedAttention的实现\n",
    "        norm(x) -> MultiHeadedAttention(x,x,x,mask) -> dropout -> +x [残差连接]\n",
    "        \n",
    "        2.3.2 feedforward类\n",
    "        norm(x) -> PositionwiseFeedForward(x) -> dropout -> +x [残差连接]\n",
    "        \n",
    "        \n",
    "        可以看出MultiHeadedAttention和feedforward结构类似，除了第二步使用的layer不一样，上述结构都通过\n",
    "        辅助类 SublayerConnection实现\n",
    "        \n",
    "        需要注意的地方:\n",
    "        在EncoderLayer的MultiHeadedAttention中,由于所有q, k, v都是来自src_emb, 所以q = k = v = x\n",
    "        \n",
    "        DecoderLayer的MultiHeadedAttention的区别在DecoderLayer部分说明\n",
    "    \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3735e",
   "metadata": {},
   "source": [
    "#### 实现Embedding和PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = make_model(11,11,2)\n",
    "# 其他模型参数: d_model=512, d_ff=2-48, h=8, dropout=0.1\n",
    "# src_vocab = 11\n",
    "# tgt_vocab = 11\n",
    "# train the model to memorize the numbers of 1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2f07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# src\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) # src\n",
    "print(src)\n",
    "# batch=1 \n",
    "print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b519bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
      "torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 创建mask\n",
    "src_mask = torch.ones(1,1,10)\n",
    "print(src_mask)\n",
    "print(src_mask.shape) # 为什么这么设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015200c1",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3921acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = test_model.encoder(src_emb(src), src_mask)\n",
    "# memory为encoder的结果\n",
    "import math\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings,self).__init__()\n",
    "        self.lut = nn.Embedding(vocab,d_model)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Q: 为什么要进行缩放\n",
    "        # https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/\n",
    "        return self.lut(x) * math.sqrt(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540ba07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# embedding_test\n",
    "embedding = nn.Embedding(11,512)\n",
    "embedding_output = embedding(src)\n",
    "print(embedding_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf79f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "embedding_output = embedding_output * math.sqrt(512)\n",
    "print(embedding_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfcb7bc",
   "metadata": {},
   "source": [
    "#### positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238aa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(embedding, position)\n",
    "# position = PositionalEncoding(512,dropout=0.1)\n",
    "# 因为缺少位置信息\n",
    "# inject information about relative and absolute\n",
    "# position of the tokens\n",
    "\n",
    "# positional encoding\n",
    "# 公式\n",
    "# PE(pos,2i) = sin(pos/10000**(2*i/d_model))\n",
    "# PE(pos,2i+1) = cos(pos/10000**(2*i/d_model))\n",
    "\n",
    "# for any fixed offset k\n",
    "# PE(pos+k) can be represented as a linear function of PEpos\n",
    "\n",
    "# apply Pdrop=0.1 to the result\n",
    "# 注意max_length的设定\n",
    "\n",
    "# 还有其他提供位置信息的方法\n",
    "# 例如: rotary embedding\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        # 设定句子长度为5000\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # compute the positional encodings once in log space\n",
    "        \n",
    "        # 创建position和d_mode的矩阵\n",
    "        pe = torch.zeros(max_len, d_model) # 矩阵 [5000,512], 设定句子长度最长5000\n",
    "        position = torch.arange(0,max_len).unsqueeze(1) # [5000,1]\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2) * -(math.log(10000.0)/d_model)) # [256]\n",
    "        pe[:,0::2] = torch.sin(position * div_term) # [256]\n",
    "        pe[:,1::2] = torch.cos(position * div_term) # [256]\n",
    "        \n",
    "        pe = pe.unsqueeze(0) # [1,5000,152]\n",
    "        self.register_buffer(\"pe\",pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x.size(1) 截取前10个位置的PE\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False) # [1,10,512]\n",
    "        return self.dropout(x) # [1,10,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db984ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 512])\n"
     ]
    }
   ],
   "source": [
    "# positional encoding test\n",
    "max_len = 5000 #句子长度\n",
    "d_model = 512\n",
    "pe = torch.zeros(5000, 512)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb41b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,    1,    2,  ..., 4997, 4998, 4999])\n",
      "torch.Size([5000])\n",
      "torch.Size([5000, 1])\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(0,5000)\n",
    "print(position)\n",
    "print(position.shape)\n",
    "position = position.unsqueeze(1)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ede84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "div_term = torch.exp(\n",
    "            torch.arange(0, 512, 2) * -(math.log(10000.0) / 512)\n",
    "        )\n",
    "print(div_term.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfaa6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 256])\n"
     ]
    }
   ],
   "source": [
    "print((position * div_term).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc108e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 512])\n"
     ]
    }
   ],
   "source": [
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20873e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5000, 512])\n"
     ]
    }
   ],
   "source": [
    "pe = pe.unsqueeze(0)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d676745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(embedding_output.size(1))  # 1.10,512\n",
    "\n",
    "test = pe[:,:embedding_output.size(1)] # 截取前10个\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba9f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "embedding_position = embedding_output + pe[:,:embedding_output.size(1)]\n",
    "print(embedding_position.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48158153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsqueeze函数的使用方法\n",
    "# torch.unsqueeze(input,dim)\n",
    "# squeeze 和 unsqueeze的参数都是指维度\n",
    "x = torch.tensor([1,2,3,4])\n",
    "torch.unsqueeze(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417b9b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbde11c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# 各种形状变换\n",
    "dropout = nn.Dropout(p=0.1)\n",
    "embedding_position = dropout(embedding_position)\n",
    "print(embedding_position.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc2392c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8c5cc379a11c4f37a1db0e739deecd64.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8c5cc379a11c4f37a1db0e739deecd64.vega-embed details,\n",
       "  #altair-viz-8c5cc379a11c4f37a1db0e739deecd64.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8c5cc379a11c4f37a1db0e739deecd64\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8c5cc379a11c4f37a1db0e739deecd64\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8c5cc379a11c4f37a1db0e739deecd64\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-19e5b2943325a93b54672b5ab669c4cc\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"dimension\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-19e5b2943325a93b54672b5ab669c4cc\": [{\"embedding\": 0.0, \"dimension\": 4, \"position\": 0}, {\"embedding\": 0.15782663226127625, \"dimension\": 4, \"position\": 1}, {\"embedding\": 0.3116971552371979, \"dimension\": 4, \"position\": 2}, {\"embedding\": 0.45775455236434937, \"dimension\": 4, \"position\": 3}, {\"embedding\": 0.5923377275466919, \"dimension\": 4, \"position\": 4}, {\"embedding\": 0.7120732069015503, \"dimension\": 4, \"position\": 5}, {\"embedding\": 0.813959538936615, \"dimension\": 4, \"position\": 6}, {\"embedding\": 0.8954429626464844, \"dimension\": 4, \"position\": 7}, {\"embedding\": 0.9544808864593506, \"dimension\": 4, \"position\": 8}, {\"embedding\": 0.989593505859375, \"dimension\": 4, \"position\": 9}, {\"embedding\": 0.9999006390571594, \"dimension\": 4, \"position\": 10}, {\"embedding\": 0.9851439595222473, \"dimension\": 4, \"position\": 11}, {\"embedding\": 0.94569331407547, \"dimension\": 4, \"position\": 12}, {\"embedding\": 0.8825376033782959, \"dimension\": 4, \"position\": 13}, {\"embedding\": 0.7972599267959595, \"dimension\": 4, \"position\": 14}, {\"embedding\": 0.6919978260993958, \"dimension\": 4, \"position\": 15}, {\"embedding\": 0.5693899393081665, \"dimension\": 4, \"position\": 16}, {\"embedding\": 0.4325096309185028, \"dimension\": 4, \"position\": 17}, {\"embedding\": 0.284787654876709, \"dimension\": 4, \"position\": 18}, {\"embedding\": 0.12992730736732483, \"dimension\": 4, \"position\": 19}, {\"embedding\": -0.028190065175294876, \"dimension\": 4, \"position\": 20}, {\"embedding\": -0.18560057878494263, \"dimension\": 4, \"position\": 21}, {\"embedding\": -0.3383587896823883, \"dimension\": 4, \"position\": 22}, {\"embedding\": -0.4826357662677765, \"dimension\": 4, \"position\": 23}, {\"embedding\": -0.6148146390914917, \"dimension\": 4, \"position\": 24}, {\"embedding\": -0.7315824031829834, \"dimension\": 4, \"position\": 25}, {\"embedding\": -0.8300122618675232, \"dimension\": 4, \"position\": 26}, {\"embedding\": -0.9076365828514099, \"dimension\": 4, \"position\": 27}, {\"embedding\": -0.96250981092453, \"dimension\": 4, \"position\": 28}, {\"embedding\": -0.9932565093040466, \"dimension\": 4, \"position\": 29}, {\"embedding\": -0.9991058707237244, \"dimension\": 4, \"position\": 30}, {\"embedding\": -0.9799113273620605, \"dimension\": 4, \"position\": 31}, {\"embedding\": -0.9361540079116821, \"dimension\": 4, \"position\": 32}, {\"embedding\": -0.8689308166503906, \"dimension\": 4, \"position\": 33}, {\"embedding\": -0.7799267172813416, \"dimension\": 4, \"position\": 34}, {\"embedding\": -0.6713724136352539, \"dimension\": 4, \"position\": 35}, {\"embedding\": -0.5459895133972168, \"dimension\": 4, \"position\": 36}, {\"embedding\": -0.40692076086997986, \"dimension\": 4, \"position\": 37}, {\"embedding\": -0.2576519548892975, \"dimension\": 4, \"position\": 38}, {\"embedding\": -0.10192479938268661, \"dimension\": 4, \"position\": 39}, {\"embedding\": 0.056357722729444504, \"dimension\": 4, \"position\": 40}, {\"embedding\": 0.21322709321975708, \"dimension\": 4, \"position\": 41}, {\"embedding\": 0.3647516369819641, \"dimension\": 4, \"position\": 42}, {\"embedding\": 0.5071332454681396, \"dimension\": 4, \"position\": 43}, {\"embedding\": 0.6368028521537781, \"dimension\": 4, \"position\": 44}, {\"embedding\": 0.7505101561546326, \"dimension\": 4, \"position\": 45}, {\"embedding\": 0.8454052805900574, \"dimension\": 4, \"position\": 46}, {\"embedding\": 0.9191088080406189, \"dimension\": 4, \"position\": 47}, {\"embedding\": 0.9697737693786621, \"dimension\": 4, \"position\": 48}, {\"embedding\": 0.9961300492286682, \"dimension\": 4, \"position\": 49}, {\"embedding\": 0.9975170493125916, \"dimension\": 4, \"position\": 50}, {\"embedding\": 0.9738998413085938, \"dimension\": 4, \"position\": 51}, {\"embedding\": 0.9258706569671631, \"dimension\": 4, \"position\": 52}, {\"embedding\": 0.8546332716941833, \"dimension\": 4, \"position\": 53}, {\"embedding\": 0.7619734406471252, \"dimension\": 4, \"position\": 54}, {\"embedding\": 0.6502137184143066, \"dimension\": 4, \"position\": 55}, {\"embedding\": 0.5221555233001709, \"dimension\": 4, \"position\": 56}, {\"embedding\": 0.38100889325141907, \"dimension\": 4, \"position\": 57}, {\"embedding\": 0.23031172156333923, \"dimension\": 4, \"position\": 58}, {\"embedding\": 0.07384055852890015, \"dimension\": 4, \"position\": 59}, {\"embedding\": -0.08448058366775513, \"dimension\": 4, \"position\": 60}, {\"embedding\": -0.2406841218471527, \"dimension\": 4, \"position\": 61}, {\"embedding\": -0.3908545970916748, \"dimension\": 4, \"position\": 62}, {\"embedding\": -0.5312277674674988, \"dimension\": 4, \"position\": 63}, {\"embedding\": -0.6582850813865662, \"dimension\": 4, \"position\": 64}, {\"embedding\": -0.768841564655304, \"dimension\": 4, \"position\": 65}, {\"embedding\": -0.8601260781288147, \"dimension\": 4, \"position\": 66}, {\"embedding\": -0.9298503994941711, \"dimension\": 4, \"position\": 67}, {\"embedding\": -0.9762668013572693, \"dimension\": 4, \"position\": 68}, {\"embedding\": -0.9982118010520935, \"dimension\": 4, \"position\": 69}, {\"embedding\": -0.9951352477073669, \"dimension\": 4, \"position\": 70}, {\"embedding\": -0.967114269733429, \"dimension\": 4, \"position\": 71}, {\"embedding\": -0.9148513078689575, \"dimension\": 4, \"position\": 72}, {\"embedding\": -0.839656412601471, \"dimension\": 4, \"position\": 73}, {\"embedding\": -0.7434144616127014, \"dimension\": 4, \"position\": 74}, {\"embedding\": -0.6285378336906433, \"dimension\": 4, \"position\": 75}, {\"embedding\": -0.4979061186313629, \"dimension\": 4, \"position\": 76}, {\"embedding\": -0.3547937273979187, \"dimension\": 4, \"position\": 77}, {\"embedding\": -0.20278796553611755, \"dimension\": 4, \"position\": 78}, {\"embedding\": -0.04569905996322632, \"dimension\": 4, \"position\": 79}, {\"embedding\": 0.11253630369901657, \"dimension\": 4, \"position\": 80}, {\"embedding\": 0.2679498493671417, \"dimension\": 4, \"position\": 81}, {\"embedding\": 0.4166468679904938, \"dimension\": 4, \"position\": 82}, {\"embedding\": 0.5549001097679138, \"dimension\": 4, \"position\": 83}, {\"embedding\": 0.6792440414428711, \"dimension\": 4, \"position\": 84}, {\"embedding\": 0.7865618467330933, \"dimension\": 4, \"position\": 85}, {\"embedding\": 0.8741634488105774, \"dimension\": 4, \"position\": 86}, {\"embedding\": 0.9398530125617981, \"dimension\": 4, \"position\": 87}, {\"embedding\": 0.9819839596748352, \"dimension\": 4, \"position\": 88}, {\"embedding\": 0.9995002150535583, \"dimension\": 4, \"position\": 89}, {\"embedding\": 0.9919626712799072, \"dimension\": 4, \"position\": 90}, {\"embedding\": 0.959559977054596, \"dimension\": 4, \"position\": 91}, {\"embedding\": 0.903104841709137, \"dimension\": 4, \"position\": 92}, {\"embedding\": 0.8240122199058533, \"dimension\": 4, \"position\": 93}, {\"embedding\": 0.7242646217346191, \"dimension\": 4, \"position\": 94}, {\"embedding\": 0.6063624024391174, \"dimension\": 4, \"position\": 95}, {\"embedding\": 0.4732609689235687, \"dimension\": 4, \"position\": 96}, {\"embedding\": 0.32829657196998596, \"dimension\": 4, \"position\": 97}, {\"embedding\": 0.17510302364826202, \"dimension\": 4, \"position\": 98}, {\"embedding\": 0.01752028614282608, \"dimension\": 4, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 5, \"position\": 0}, {\"embedding\": 0.9874668121337891, \"dimension\": 5, \"position\": 1}, {\"embedding\": 0.9501814842224121, \"dimension\": 5, \"position\": 2}, {\"embedding\": 0.8890786170959473, \"dimension\": 5, \"position\": 3}, {\"embedding\": 0.805689811706543, \"dimension\": 5, \"position\": 4}, {\"embedding\": 0.7021052241325378, \"dimension\": 5, \"position\": 5}, {\"embedding\": 0.5809215307235718, \"dimension\": 5, \"position\": 6}, {\"embedding\": 0.44517630338668823, \"dimension\": 5, \"position\": 7}, {\"embedding\": 0.298272043466568, \"dimension\": 5, \"position\": 8}, {\"embedding\": 0.14389123022556305, \"dimension\": 5, \"position\": 9}, {\"embedding\": -0.01409643329679966, \"dimension\": 5, \"position\": 10}, {\"embedding\": -0.1717306226491928, \"dimension\": 5, \"position\": 11}, {\"embedding\": -0.32506027817726135, \"dimension\": 5, \"position\": 12}, {\"embedding\": -0.47024187445640564, \"dimension\": 5, \"position\": 13}, {\"embedding\": -0.6036361455917358, \"dimension\": 5, \"position\": 14}, {\"embedding\": -0.7218996286392212, \"dimension\": 5, \"position\": 15}, {\"embedding\": -0.8220675587654114, \"dimension\": 5, \"position\": 16}, {\"embedding\": -0.9016293287277222, \"dimension\": 5, \"position\": 17}, {\"embedding\": -0.9585906267166138, \"dimension\": 5, \"position\": 18}, {\"embedding\": -0.9915235042572021, \"dimension\": 5, \"position\": 19}, {\"embedding\": -0.9996025562286377, \"dimension\": 5, \"position\": 20}, {\"embedding\": -0.9826252460479736, \"dimension\": 5, \"position\": 21}, {\"embedding\": -0.941017210483551, \"dimension\": 5, \"position\": 22}, {\"embedding\": -0.8758211731910706, \"dimension\": 5, \"position\": 23}, {\"embedding\": -0.788671612739563, \"dimension\": 5, \"position\": 24}, {\"embedding\": -0.6817529797554016, \"dimension\": 5, \"position\": 25}, {\"embedding\": -0.5577451586723328, \"dimension\": 5, \"position\": 26}, {\"embedding\": -0.4197568893432617, \"dimension\": 5, \"position\": 27}, {\"embedding\": -0.27124688029289246, \"dimension\": 5, \"position\": 28}, {\"embedding\": -0.11593768745660782, \"dimension\": 5, \"position\": 29}, {\"embedding\": 0.042278096079826355, \"dimension\": 5, \"position\": 30}, {\"embedding\": 0.19943365454673767, \"dimension\": 5, \"position\": 31}, {\"embedding\": 0.3515901565551758, \"dimension\": 5, \"position\": 32}, {\"embedding\": 0.4949335753917694, \"dimension\": 5, \"position\": 33}, {\"embedding\": 0.6258708238601685, \"dimension\": 5, \"position\": 34}, {\"embedding\": 0.7411201596260071, \"dimension\": 5, \"position\": 35}, {\"embedding\": 0.8377919793128967, \"dimension\": 5, \"position\": 36}, {\"embedding\": 0.9134634733200073, \"dimension\": 5, \"position\": 37}, {\"embedding\": 0.9662377834320068, \"dimension\": 5, \"position\": 38}, {\"embedding\": 0.994792103767395, \"dimension\": 5, \"position\": 39}, {\"embedding\": 0.9984106421470642, \"dimension\": 5, \"position\": 40}, {\"embedding\": 0.9770026803016663, \"dimension\": 5, \"position\": 41}, {\"embedding\": 0.931104838848114, \"dimension\": 5, \"position\": 42}, {\"embedding\": 0.8618676662445068, \"dimension\": 5, \"position\": 43}, {\"embedding\": 0.7710266709327698, \"dimension\": 5, \"position\": 44}, {\"embedding\": 0.6608588695526123, \"dimension\": 5, \"position\": 45}, {\"embedding\": 0.5341253876686096, \"dimension\": 5, \"position\": 46}, {\"embedding\": 0.3940037488937378, \"dimension\": 5, \"position\": 47}, {\"embedding\": 0.24400585889816284, \"dimension\": 5, \"position\": 48}, {\"embedding\": 0.08789165318012238, \"dimension\": 5, \"position\": 49}, {\"embedding\": -0.07042567431926727, \"dimension\": 5, \"position\": 50}, {\"embedding\": -0.2269781529903412, \"dimension\": 5, \"position\": 51}, {\"embedding\": -0.37784066796302795, \"dimension\": 5, \"position\": 52}, {\"embedding\": -0.5192320942878723, \"dimension\": 5, \"position\": 53}, {\"embedding\": -0.6476082801818848, \"dimension\": 5, \"position\": 54}, {\"embedding\": -0.7597513794898987, \"dimension\": 5, \"position\": 55}, {\"embedding\": -0.8528502583503723, \"dimension\": 5, \"position\": 56}, {\"embedding\": -0.9245713949203491, \"dimension\": 5, \"position\": 57}, {\"embedding\": -0.9731168746948242, \"dimension\": 5, \"position\": 58}, {\"embedding\": -0.9972700476646423, \"dimension\": 5, \"position\": 59}, {\"embedding\": -0.9964251518249512, \"dimension\": 5, \"position\": 60}, {\"embedding\": -0.9706035256385803, \"dimension\": 5, \"position\": 61}, {\"embedding\": -0.9204524159431458, \"dimension\": 5, \"position\": 62}, {\"embedding\": -0.8472290635108948, \"dimension\": 5, \"position\": 63}, {\"embedding\": -0.7527687549591064, \"dimension\": 5, \"position\": 64}, {\"embedding\": -0.6394393444061279, \"dimension\": 5, \"position\": 65}, {\"embedding\": -0.5100815296173096, \"dimension\": 5, \"position\": 66}, {\"embedding\": -0.3679378628730774, \"dimension\": 5, \"position\": 67}, {\"embedding\": -0.2165713608264923, \"dimension\": 5, \"position\": 68}, {\"embedding\": -0.05977622792124748, \"dimension\": 5, \"position\": 69}, {\"embedding\": 0.09851823002099991, \"dimension\": 5, \"position\": 70}, {\"embedding\": 0.254342257976532, \"dimension\": 5, \"position\": 71}, {\"embedding\": 0.4037908613681793, \"dimension\": 5, \"position\": 72}, {\"embedding\": 0.543117880821228, \"dimension\": 5, \"position\": 73}, {\"embedding\": 0.6688309907913208, \"dimension\": 5, \"position\": 74}, {\"embedding\": 0.7777789831161499, \"dimension\": 5, \"position\": 75}, {\"embedding\": 0.8672309517860413, \"dimension\": 5, \"position\": 76}, {\"embedding\": 0.9349446296691895, \"dimension\": 5, \"position\": 77}, {\"embedding\": 0.9792226552963257, \"dimension\": 5, \"position\": 78}, {\"embedding\": 0.998955249786377, \"dimension\": 5, \"position\": 79}, {\"embedding\": 0.9936476349830627, \"dimension\": 5, \"position\": 80}, {\"embedding\": 0.9634328484535217, \"dimension\": 5, \"position\": 81}, {\"embedding\": 0.9090684056282043, \"dimension\": 5, \"position\": 82}, {\"embedding\": 0.8319169878959656, \"dimension\": 5, \"position\": 83}, {\"embedding\": 0.733912467956543, \"dimension\": 5, \"position\": 84}, {\"embedding\": 0.617511510848999, \"dimension\": 5, \"position\": 85}, {\"embedding\": 0.4856317937374115, \"dimension\": 5, \"position\": 86}, {\"embedding\": 0.3415791094303131, \"dimension\": 5, \"position\": 87}, {\"embedding\": 0.18896427750587463, \"dimension\": 5, \"position\": 88}, {\"embedding\": 0.0316128134727478, \"dimension\": 5, \"position\": 89}, {\"embedding\": -0.12653106451034546, \"dimension\": 5, \"position\": 90}, {\"embedding\": -0.28150418400764465, \"dimension\": 5, \"position\": 91}, {\"embedding\": -0.4294200837612152, \"dimension\": 5, \"position\": 92}, {\"embedding\": -0.5665720105171204, \"dimension\": 5, \"position\": 93}, {\"embedding\": -0.6895220875740051, \"dimension\": 5, \"position\": 94}, {\"embedding\": -0.7951884269714355, \"dimension\": 5, \"position\": 95}, {\"embedding\": -0.880922257900238, \"dimension\": 5, \"position\": 96}, {\"embedding\": -0.9445747137069702, \"dimension\": 5, \"position\": 97}, {\"embedding\": -0.9845501184463501, \"dimension\": 5, \"position\": 98}, {\"embedding\": -0.9998465180397034, \"dimension\": 5, \"position\": 99}, {\"embedding\": 0.0, \"dimension\": 6, \"position\": 0}, {\"embedding\": 0.06305388361215591, \"dimension\": 6, \"position\": 1}, {\"embedding\": 0.12585683166980743, \"dimension\": 6, \"position\": 2}, {\"embedding\": 0.18815888464450836, \"dimension\": 6, \"position\": 3}, {\"embedding\": 0.24971213936805725, \"dimension\": 6, \"position\": 4}, {\"embedding\": 0.31027159094810486, \"dimension\": 6, \"position\": 5}, {\"embedding\": 0.3695962131023407, \"dimension\": 6, \"position\": 6}, {\"embedding\": 0.4274499714374542, \"dimension\": 6, \"position\": 7}, {\"embedding\": 0.4836025834083557, \"dimension\": 6, \"position\": 8}, {\"embedding\": 0.5378305315971375, \"dimension\": 6, \"position\": 9}, {\"embedding\": 0.5899181365966797, \"dimension\": 6, \"position\": 10}, {\"embedding\": 0.6396579146385193, \"dimension\": 6, \"position\": 11}, {\"embedding\": 0.6868520379066467, \"dimension\": 6, \"position\": 12}, {\"embedding\": 0.7313126921653748, \"dimension\": 6, \"position\": 13}, {\"embedding\": 0.7728629112243652, \"dimension\": 6, \"position\": 14}, {\"embedding\": 0.8113372921943665, \"dimension\": 6, \"position\": 15}, {\"embedding\": 0.8465827703475952, \"dimension\": 6, \"position\": 16}, {\"embedding\": 0.8784590363502502, \"dimension\": 6, \"position\": 17}, {\"embedding\": 0.9068393111228943, \"dimension\": 6, \"position\": 18}, {\"embedding\": 0.9316105246543884, \"dimension\": 6, \"position\": 19}, {\"embedding\": 0.9526742100715637, \"dimension\": 6, \"position\": 20}, {\"embedding\": 0.9699464440345764, \"dimension\": 6, \"position\": 21}, {\"embedding\": 0.9833585619926453, \"dimension\": 6, \"position\": 22}, {\"embedding\": 0.9928570985794067, \"dimension\": 6, \"position\": 23}, {\"embedding\": 0.9984043836593628, \"dimension\": 6, \"position\": 24}, {\"embedding\": 0.999978244304657, \"dimension\": 6, \"position\": 25}, {\"embedding\": 0.9975724220275879, \"dimension\": 6, \"position\": 26}, {\"embedding\": 0.9911965131759644, \"dimension\": 6, \"position\": 27}, {\"embedding\": 0.9808759093284607, \"dimension\": 6, \"position\": 28}, {\"embedding\": 0.9666516184806824, \"dimension\": 6, \"position\": 29}, {\"embedding\": 0.9485803842544556, \"dimension\": 6, \"position\": 30}, {\"embedding\": 0.9267339110374451, \"dimension\": 6, \"position\": 31}, {\"embedding\": 0.9011994004249573, \"dimension\": 6, \"position\": 32}, {\"embedding\": 0.8720782399177551, \"dimension\": 6, \"position\": 33}, {\"embedding\": 0.8394865393638611, \"dimension\": 6, \"position\": 34}, {\"embedding\": 0.8035537600517273, \"dimension\": 6, \"position\": 35}, {\"embedding\": 0.7644230127334595, \"dimension\": 6, \"position\": 36}, {\"embedding\": 0.7222501039505005, \"dimension\": 6, \"position\": 37}, {\"embedding\": 0.6772029399871826, \"dimension\": 6, \"position\": 38}, {\"embedding\": 0.6294605135917664, \"dimension\": 6, \"position\": 39}, {\"embedding\": 0.57921302318573, \"dimension\": 6, \"position\": 40}, {\"embedding\": 0.5266605615615845, \"dimension\": 6, \"position\": 41}, {\"embedding\": 0.4720119535923004, \"dimension\": 6, \"position\": 42}, {\"embedding\": 0.41548484563827515, \"dimension\": 6, \"position\": 43}, {\"embedding\": 0.357304185628891, \"dimension\": 6, \"position\": 44}, {\"embedding\": 0.29770180583000183, \"dimension\": 6, \"position\": 45}, {\"embedding\": 0.23691438138484955, \"dimension\": 6, \"position\": 46}, {\"embedding\": 0.17518411576747894, \"dimension\": 6, \"position\": 47}, {\"embedding\": 0.1127568930387497, \"dimension\": 6, \"position\": 48}, {\"embedding\": 0.04988069087266922, \"dimension\": 6, \"position\": 49}, {\"embedding\": -0.013194027356803417, \"dimension\": 6, \"position\": 50}, {\"embedding\": -0.07621623575687408, \"dimension\": 6, \"position\": 51}, {\"embedding\": -0.1389348804950714, \"dimension\": 6, \"position\": 52}, {\"embedding\": -0.20110084116458893, \"dimension\": 6, \"position\": 53}, {\"embedding\": -0.2624664604663849, \"dimension\": 6, \"position\": 54}, {\"embedding\": -0.3227875530719757, \"dimension\": 6, \"position\": 55}, {\"embedding\": -0.3818237781524658, \"dimension\": 6, \"position\": 56}, {\"embedding\": -0.4393406808376312, \"dimension\": 6, \"position\": 57}, {\"embedding\": -0.49510911107063293, \"dimension\": 6, \"position\": 58}, {\"embedding\": -0.5489069223403931, \"dimension\": 6, \"position\": 59}, {\"embedding\": -0.6005204319953918, \"dimension\": 6, \"position\": 60}, {\"embedding\": -0.6497439742088318, \"dimension\": 6, \"position\": 61}, {\"embedding\": -0.6963817477226257, \"dimension\": 6, \"position\": 62}, {\"embedding\": -0.7402478456497192, \"dimension\": 6, \"position\": 63}, {\"embedding\": -0.7811681628227234, \"dimension\": 6, \"position\": 64}, {\"embedding\": -0.8189795017242432, \"dimension\": 6, \"position\": 65}, {\"embedding\": -0.8535317778587341, \"dimension\": 6, \"position\": 66}, {\"embedding\": -0.8846868872642517, \"dimension\": 6, \"position\": 67}, {\"embedding\": -0.9123212099075317, \"dimension\": 6, \"position\": 68}, {\"embedding\": -0.936324954032898, \"dimension\": 6, \"position\": 69}, {\"embedding\": -0.9566020965576172, \"dimension\": 6, \"position\": 70}, {\"embedding\": -0.9730724096298218, \"dimension\": 6, \"position\": 71}, {\"embedding\": -0.9856699705123901, \"dimension\": 6, \"position\": 72}, {\"embedding\": -0.9943448305130005, \"dimension\": 6, \"position\": 73}, {\"embedding\": -0.9990625381469727, \"dimension\": 6, \"position\": 74}, {\"embedding\": -0.9998041391372681, \"dimension\": 6, \"position\": 75}, {\"embedding\": -0.9965668320655823, \"dimension\": 6, \"position\": 76}, {\"embedding\": -0.9893633723258972, \"dimension\": 6, \"position\": 77}, {\"embedding\": -0.9782225489616394, \"dimension\": 6, \"position\": 78}, {\"embedding\": -0.963188648223877, \"dimension\": 6, \"position\": 79}, {\"embedding\": -0.9443213939666748, \"dimension\": 6, \"position\": 80}, {\"embedding\": -0.9216960668563843, \"dimension\": 6, \"position\": 81}, {\"embedding\": -0.8954026699066162, \"dimension\": 6, \"position\": 82}, {\"embedding\": -0.8655455708503723, \"dimension\": 6, \"position\": 83}, {\"embedding\": -0.8322440981864929, \"dimension\": 6, \"position\": 84}, {\"embedding\": -0.795630156993866, \"dimension\": 6, \"position\": 85}, {\"embedding\": -0.7558501362800598, \"dimension\": 6, \"position\": 86}, {\"embedding\": -0.7130619883537292, \"dimension\": 6, \"position\": 87}, {\"embedding\": -0.6674357056617737, \"dimension\": 6, \"position\": 88}, {\"embedding\": -0.6191535592079163, \"dimension\": 6, \"position\": 89}, {\"embedding\": -0.5684073567390442, \"dimension\": 6, \"position\": 90}, {\"embedding\": -0.5153986215591431, \"dimension\": 6, \"position\": 91}, {\"embedding\": -0.46033912897109985, \"dimension\": 6, \"position\": 92}, {\"embedding\": -0.40344759821891785, \"dimension\": 6, \"position\": 93}, {\"embedding\": -0.34495002031326294, \"dimension\": 6, \"position\": 94}, {\"embedding\": -0.28508007526397705, \"dimension\": 6, \"position\": 95}, {\"embedding\": -0.22407560050487518, \"dimension\": 6, \"position\": 96}, {\"embedding\": -0.1621788740158081, \"dimension\": 6, \"position\": 97}, {\"embedding\": -0.09963719546794891, \"dimension\": 6, \"position\": 98}, {\"embedding\": -0.03669850528240204, \"dimension\": 6, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 7, \"position\": 0}, {\"embedding\": 0.9980100989341736, \"dimension\": 7, \"position\": 1}, {\"embedding\": 0.992048442363739, \"dimension\": 7, \"position\": 2}, {\"embedding\": 0.9821385741233826, \"dimension\": 7, \"position\": 3}, {\"embedding\": 0.9683201313018799, \"dimension\": 7, \"position\": 4}, {\"embedding\": 0.9506479501724243, \"dimension\": 7, \"position\": 5}, {\"embedding\": 0.9291924834251404, \"dimension\": 7, \"position\": 6}, {\"embedding\": 0.9040390253067017, \"dimension\": 7, \"position\": 7}, {\"embedding\": 0.8752877116203308, \"dimension\": 7, \"position\": 8}, {\"embedding\": 0.8430529832839966, \"dimension\": 7, \"position\": 9}, {\"embedding\": 0.8074630498886108, \"dimension\": 7, \"position\": 10}, {\"embedding\": 0.7686597108840942, \"dimension\": 7, \"position\": 11}, {\"embedding\": 0.7267972826957703, \"dimension\": 7, \"position\": 12}, {\"embedding\": 0.6820423603057861, \"dimension\": 7, \"position\": 13}, {\"embedding\": 0.6345730423927307, \"dimension\": 7, \"position\": 14}, {\"embedding\": 0.5845783352851868, \"dimension\": 7, \"position\": 15}, {\"embedding\": 0.532257080078125, \"dimension\": 7, \"position\": 16}, {\"embedding\": 0.47781768441200256, \"dimension\": 7, \"position\": 17}, {\"embedding\": 0.4214765727519989, \"dimension\": 7, \"position\": 18}, {\"embedding\": 0.36345818638801575, \"dimension\": 7, \"position\": 19}, {\"embedding\": 0.30399322509765625, \"dimension\": 7, \"position\": 20}, {\"embedding\": 0.243318572640419, \"dimension\": 7, \"position\": 21}, {\"embedding\": 0.18167544901371002, \"dimension\": 7, \"position\": 22}, {\"embedding\": 0.11930941045284271, \"dimension\": 7, \"position\": 23}, {\"embedding\": 0.056468550115823746, \"dimension\": 7, \"position\": 24}, {\"embedding\": -0.006597157102078199, \"dimension\": 7, \"position\": 25}, {\"embedding\": -0.06963648647069931, \"dimension\": 7, \"position\": 26}, {\"embedding\": -0.1323987990617752, \"dimension\": 7, \"position\": 27}, {\"embedding\": -0.1946340948343277, \"dimension\": 7, \"position\": 28}, {\"embedding\": -0.25609490275382996, \"dimension\": 7, \"position\": 29}, {\"embedding\": -0.31653639674186707, \"dimension\": 7, \"position\": 30}, {\"embedding\": -0.37571826577186584, \"dimension\": 7, \"position\": 31}, {\"embedding\": -0.43340474367141724, \"dimension\": 7, \"position\": 32}, {\"embedding\": -0.4893665015697479, \"dimension\": 7, \"position\": 33}, {\"embedding\": -0.5433804988861084, \"dimension\": 7, \"position\": 34}, {\"embedding\": -0.5952321887016296, \"dimension\": 7, \"position\": 35}, {\"embedding\": -0.6447150111198425, \"dimension\": 7, \"position\": 36}, {\"embedding\": -0.6916319727897644, \"dimension\": 7, \"position\": 37}, {\"embedding\": -0.7357962727546692, \"dimension\": 7, \"position\": 38}, {\"embedding\": -0.7770324349403381, \"dimension\": 7, \"position\": 39}, {\"embedding\": -0.815176248550415, \"dimension\": 7, \"position\": 40}, {\"embedding\": -0.8500756621360779, \"dimension\": 7, \"position\": 41}, {\"embedding\": -0.8815921545028687, \"dimension\": 7, \"position\": 42}, {\"embedding\": -0.9096000790596008, \"dimension\": 7, \"position\": 43}, {\"embedding\": -0.933988094329834, \"dimension\": 7, \"position\": 44}, {\"embedding\": -0.9546589255332947, \"dimension\": 7, \"position\": 45}, {\"embedding\": -0.971530556678772, \"dimension\": 7, \"position\": 46}, {\"embedding\": -0.9845356941223145, \"dimension\": 7, \"position\": 47}, {\"embedding\": -0.9936226010322571, \"dimension\": 7, \"position\": 48}, {\"embedding\": -0.998755156993866, \"dimension\": 7, \"position\": 49}, {\"embedding\": -0.9999129772186279, \"dimension\": 7, \"position\": 50}, {\"embedding\": -0.9970912933349609, \"dimension\": 7, \"position\": 51}, {\"embedding\": -0.9903014898300171, \"dimension\": 7, \"position\": 52}, {\"embedding\": -0.9795705676078796, \"dimension\": 7, \"position\": 53}, {\"embedding\": -0.9649410843849182, \"dimension\": 7, \"position\": 54}, {\"embedding\": -0.9464714527130127, \"dimension\": 7, \"position\": 55}, {\"embedding\": -0.9242351651191711, \"dimension\": 7, \"position\": 56}, {\"embedding\": -0.8983205556869507, \"dimension\": 7, \"position\": 57}, {\"embedding\": -0.8688308000564575, \"dimension\": 7, \"position\": 58}, {\"embedding\": -0.8358834981918335, \"dimension\": 7, \"position\": 59}, {\"embedding\": -0.7996094226837158, \"dimension\": 7, \"position\": 60}, {\"embedding\": -0.7601531147956848, \"dimension\": 7, \"position\": 61}, {\"embedding\": -0.7176715731620789, \"dimension\": 7, \"position\": 62}, {\"embedding\": -0.6723340749740601, \"dimension\": 7, \"position\": 63}, {\"embedding\": -0.6243206262588501, \"dimension\": 7, \"position\": 64}, {\"embedding\": -0.5738227963447571, \"dimension\": 7, \"position\": 65}, {\"embedding\": -0.5210408568382263, \"dimension\": 7, \"position\": 66}, {\"embedding\": -0.46618568897247314, \"dimension\": 7, \"position\": 67}, {\"embedding\": -0.4094752371311188, \"dimension\": 7, \"position\": 68}, {\"embedding\": -0.3511347472667694, \"dimension\": 7, \"position\": 69}, {\"embedding\": -0.2913972735404968, \"dimension\": 7, \"position\": 70}, {\"embedding\": -0.23049965500831604, \"dimension\": 7, \"position\": 71}, {\"embedding\": -0.1686851680278778, \"dimension\": 7, \"position\": 72}, {\"embedding\": -0.10619935393333435, \"dimension\": 7, \"position\": 73}, {\"embedding\": -0.04329042136669159, \"dimension\": 7, \"position\": 74}, {\"embedding\": 0.019790323451161385, \"dimension\": 7, \"position\": 75}, {\"embedding\": 0.08279230445623398, \"dimension\": 7, \"position\": 76}, {\"embedding\": 0.14546526968479156, \"dimension\": 7, \"position\": 77}, {\"embedding\": 0.20755885541439056, \"dimension\": 7, \"position\": 78}, {\"embedding\": 0.2688263952732086, \"dimension\": 7, \"position\": 79}, {\"embedding\": 0.3290245532989502, \"dimension\": 7, \"position\": 80}, {\"embedding\": 0.3879128098487854, \"dimension\": 7, \"position\": 81}, {\"embedding\": 0.4452572762966156, \"dimension\": 7, \"position\": 82}, {\"embedding\": 0.5008301138877869, \"dimension\": 7, \"position\": 83}, {\"embedding\": 0.5544094443321228, \"dimension\": 7, \"position\": 84}, {\"embedding\": 0.605782687664032, \"dimension\": 7, \"position\": 85}, {\"embedding\": 0.6547446846961975, \"dimension\": 7, \"position\": 86}, {\"embedding\": 0.7011010050773621, \"dimension\": 7, \"position\": 87}, {\"embedding\": 0.7446674108505249, \"dimension\": 7, \"position\": 88}, {\"embedding\": 0.7852699160575867, \"dimension\": 7, \"position\": 89}, {\"embedding\": 0.8227472901344299, \"dimension\": 7, \"position\": 90}, {\"embedding\": 0.856950581073761, \"dimension\": 7, \"position\": 91}, {\"embedding\": 0.8877431154251099, \"dimension\": 7, \"position\": 92}, {\"embedding\": 0.9150027632713318, \"dimension\": 7, \"position\": 93}, {\"embedding\": 0.9386210441589355, \"dimension\": 7, \"position\": 94}, {\"embedding\": 0.9585037231445312, \"dimension\": 7, \"position\": 95}, {\"embedding\": 0.9745717644691467, \"dimension\": 7, \"position\": 96}, {\"embedding\": 0.9867613911628723, \"dimension\": 7, \"position\": 97}, {\"embedding\": 0.9950238466262817, \"dimension\": 7, \"position\": 98}, {\"embedding\": 0.9993264079093933, \"dimension\": 7, \"position\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "RUN_EXAMPLES = True\n",
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None\n",
    "    \n",
    "    \n",
    "def example_positional():\n",
    "    pe = PositionalEncoding(20, 0)\n",
    "    y = pe.forward(torch.zeros(1, 100, 20))\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"embedding\": y[0, :, dim],\n",
    "                    \"dimension\": dim,\n",
    "                    \"position\": list(range(100)),\n",
    "                }\n",
    "            )\n",
    "            for dim in [4, 5, 6, 7]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=800)\n",
    "        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_positional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce78c1",
   "metadata": {},
   "source": [
    "#### 实验EncoderLayer类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4858a",
   "metadata": {},
   "source": [
    "#### encoder\n",
    "#### 实验LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ed1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder(EncoderLayer(d_model=512, c(attn), c(ff), dropout=0.1),N=6)\n",
    "# c = copy.deepcopy\n",
    "\n",
    "# layer normalization\n",
    "# 原理看论文\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        std = x.std(-1,keepdim=True)\n",
    "        return self.a_2 * (x-mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54541b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer normalization test\n",
    "# d_model = 512\n",
    "# attn = MultiHeadedAttention(h=8, d_model=512)\n",
    "# ff = PositionwiseFeedForward(d_model=512, d_ff=2048)\n",
    "# Encoder(EncoderLayer(d_model, attn, ff, dropout),N=6)\n",
    "# size = d_model = 512\n",
    "\n",
    "a_2 = nn.Parameter(torch.ones(512))\n",
    "a_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b45048a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_2 = nn.Parameter(torch.zeros(512))\n",
    "b_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b35fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1])\n",
      "torch.Size([1, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "mean = embedding_position.mean(-1,keepdim=True)\n",
    "print(mean.shape)\n",
    "std = embedding_position.std(-1,keepdim=True)\n",
    "print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38a2e183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "embedding_position = a_2 * (embedding_position - mean) / (std + eps) + b_2\n",
    "embedding_position.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc079679",
   "metadata": {},
   "source": [
    "#### 实验MultiHeadedAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42cbe83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x -> embedding_position\n",
    "# 多头注意力\n",
    "import copy\n",
    "def clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70748c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embedding_position\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ee2e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn = MultiHeadedAttention(h=8, d_model=512)\n",
    "# 传入参数 (x,x,x,mask)\n",
    "# x -> [1,10,512]\n",
    "# mask = src_mask\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention,self).__init__()\n",
    "        assert d_model %h==0\n",
    "        \n",
    "        # we assume d_v==d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        # 前3个linear用于query,key,value的linear projections\n",
    "        # 最后一个linear用于attention之后的projection\n",
    "        self.linears = clones(nn.Linear(d_model,d_model),4)\n",
    "        \n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        \n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # do all the linear projections in batch from\n",
    "        # d_model = h * d_k\n",
    "        query, key, value = [lin(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for lin,x in zip(self.linears, (query,key,value))]\n",
    "        \n",
    "        # apply attention on all the projected vectors in batch\n",
    "        x, self.attn = attention(query, key, value, dropout=self.dropout)\n",
    "        \n",
    "        # concat\n",
    "        x = (x.transpose(1,2).contiguous().view(nbatches, -1, self.h * self.d_k))\n",
    "        \n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17fc0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b38c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# multiheaded attention \n",
    "h = 8\n",
    "d_model = 512\n",
    "#print(d_model//h) #64\n",
    "d_k = d_model // h\n",
    "print(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff1739e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = key = value = x -> [1,10,512]\n",
    "src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c435e969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask = src_mask.unsqueeze(1)\n",
    "src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b77f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# query和key的维度一样，value一个维度\n",
    "# 实验中q, k, v维度一样\n",
    "query = key = value = x # [1,10,512]\n",
    "n_batches = query.size(0)\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6cc1b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linears = clones(nn.Linear(512,512),4)\n",
    "print(linears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7c1f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Linear(in_features=512, out_features=512, bias=True)\n",
      "torch.Size([1, 10, 512])\n",
      "tensor([[[True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         ...,\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True],\n",
      "         [True, True, True,  ..., True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "test = list(zip(linears, (query,key,value)))\n",
    "print(len(test))\n",
    "#print(test[0])\n",
    "test_zero = list(test[0])\n",
    "print(test_zero[0])\n",
    "print(test_zero[1].shape)\n",
    "print(test_zero[1]==value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5503e177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x00000214E1803B40>\n",
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "# zip的用法\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "zipped = zip(a,b)\n",
    "print(zipped)\n",
    "temp = list(zipped)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d0e2e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "temp = (query,key,value)\n",
    "print(type(temp))\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63eae3f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n",
      "torch.Size([1, 10, 8, 64])\n",
      "torch.Size([1, 8, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# 简单示例\n",
    "# 实现 lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "linear_temp = nn.Linear(512,512)\n",
    "linear_output = linear_temp(query)\n",
    "print(linear_output.shape)\n",
    "linear_view = linear_output.view(1,-1,8,64)\n",
    "print(linear_view.shape)\n",
    "linear_transpose = linear_view.transpose(1,2)\n",
    "print(linear_transpose.shape)\n",
    "# 不知道为什么这里要做transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c378bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query, key, value = [\n",
    "            lin(x).view(1, -1, 8, 64).transpose(1, 2)\n",
    "            for lin, x in zip(linears, (query, key, value))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2188940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 10, 64])\n",
      "torch.Size([1, 8, 10, 64])\n",
      "torch.Size([1, 8, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# 检查query, key, value形状\n",
    "print(query.shape)\n",
    "print(key.shape)\n",
    "print(value.shape) # batch, h, token_num, d_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43148dbf",
   "metadata": {},
   "source": [
    "#### attention的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6565fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    # 计算 scaled dot product attention\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = socres.masked_fill(mask==0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn,value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d69b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "torch.Size([1, 8, 64, 10])\n",
      "torch.Size([1, 8, 10, 10])\n",
      "torch.Size([1, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实现x, self.attn = attention(\n",
    "#            query, key, value, mask=mask, dropout=self.dropout\n",
    "#        )\n",
    "\n",
    "d_k = query.size(-1)\n",
    "print(d_k) # torch.Size([1, 8, 10, 64]\n",
    "key_trans = key.transpose(-2,-1) # 这里的维度是指trans之前的维度\n",
    "print(key_trans.shape)\n",
    "scores = torch.matmul(query,key_trans)\n",
    "print(scores.shape)\n",
    "scores = scores / math.sqrt(d_k)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b48fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode不需要mask\n",
    "# masked_fill的具体用法\n",
    "scores_mask = scores.masked_fill(src_mask==0,-1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aca6386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(scores_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d46e292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "p_attn = scores.softmax(dim=-1)\n",
    "print(p_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3babde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_attn = dropout(p_attn)\n",
    "x_attn = torch.matmul(p_attn,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6cd933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 10, 64])\n",
      "torch.Size([1, 8, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(x_attn.shape)\n",
    "print(p_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a3cb6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "# \"concat\" using a view and apply a final layer \n",
    "# 实验 x = (x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k))\n",
    "x_attn_trans = x_attn.transpose(1,2) # [1,8,10,64]\n",
    "print(x_attn_trans.shape) # 恢复到原来的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d040de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "# contiguous用法\n",
    "# https://stackoverflow.com/questions/48915810/what-does-contiguous-do-in-pytorch\n",
    "x_attn_trans = x_attn_trans.contiguous()\n",
    "print(x_attn_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a495d0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "x_attn_trans = x_attn_trans.view(1,-1,8*64)\n",
    "print(x_attn_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89e0cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "x_attn_trans = linears[-1](x_attn_trans)\n",
    "print(x_attn_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f87ac",
   "metadata": {},
   "source": [
    "#### SublayerConnection最后两步实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faba13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# dropout + 残差连接\n",
    "dropout = nn.Dropout(0.1)\n",
    "sublayer1_output = x_attn_trans + dropout(x_attn_trans)\n",
    "print(sublayer1_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "在获得sublayer1的输出之后，传入sublayer2\n",
    "sublayer2: norm(x) -> PositionwiseFeedForward(x) -> dropout -> +x [残差连接]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bca53",
   "metadata": {},
   "source": [
    "#### sublayer2的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6436d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "sublayer2_norm = dropout(sublayer1_output)\n",
    "print(sublayer2_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f82a590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现PositionwiseFeedForward类\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward,self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model,d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # self.w_1\n",
    "        # relu()\n",
    "        # dropout\n",
    "        # self.w_2\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55230b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 2048])\n"
     ]
    }
   ],
   "source": [
    "w_1 = nn.Linear(512,2048)\n",
    "w_2 = nn.Linear(2048,512)\n",
    "\n",
    "position_temp = w_1(sublayer2_norm).relu()\n",
    "print(position_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c66d7e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 2048])\n"
     ]
    }
   ],
   "source": [
    "pos_temp = dropout(position_temp)\n",
    "print(pos_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41cd139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "sublayer2_pos = w_2(pos_temp)\n",
    "print(sublayer2_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37202f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# sublayer2 最后两步: dropout + 残差连接\n",
    "dropout = nn.Dropout(0.1)\n",
    "sublayer2_output = sublayer2_pos + dropout(sublayer2_pos)\n",
    "print(sublayer2_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a3f2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上就是单个EncoderLayer实验的过程\n",
    "# EncoderLayer类实现如下\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1a0bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EncoderLayer中的SublayerConnection实现过程如下\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "961b2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder的实现\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,layer,N):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "# Encoder = 6个EncoderLayer层 + 1个LayerNorm层\n",
    "# 在上面得到第一个EncoderLayer层的输出sublayer2_ouput之后\n",
    "# 把它传入第2个EncoderLayer层\n",
    "# 第2个EncoderLayer层的输出再当作输入传入下一个EncoderLayer\n",
    "# 依次类推\n",
    "# 在得到最后一个EncoderLayer的输出之后进行LayerNorm\n",
    "# 就得到了Encoder的最后结果即前文提到的memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989d1ee",
   "metadata": {},
   "source": [
    "##### 创建简单Encoder相关类获得memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d32004aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建EncoderTest\n",
    "# 用于简单获得memory\n",
    "class EncoderTest(nn.Module):\n",
    "    def __init__(self,encoder,src_embed):\n",
    "        super(EncoderTest,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        \n",
    "    def forward(self,src,src_mask):\n",
    "        return self.encode(src,src_mask)\n",
    "    \n",
    "    def encode(self,src,src_mask):\n",
    "        return self.encoder(self.src_embed(src),src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dad9539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建make_encoder模型\n",
    "# \n",
    "def make_encoder(src_vocab,N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderTest(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position))\n",
    "    )\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d01a337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([1, 1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(src.shape)\n",
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "412fe3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "test_model = make_encoder(11) # N=2\n",
    "# 实验memory = test_model.encode(src, src_mask)\n",
    "memory = test_model.encode(src,src_mask)\n",
    "print(memory.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3892b89",
   "metadata": {},
   "source": [
    "#### 实验decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "在上述encode部分已经获得了encoder的结果memory\n",
    "\n",
    "接下来继续试验decode\n",
    "\n",
    "实验inference_test()中的\n",
    "out = test_model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        \n",
    "与EncoderDecoder的作用相同\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "其中:\n",
    "decoder = Decoder(DecoderLayer(d_model=512,c(attn),c(attn),c(ff), dropout=0.1),N)\n",
    "tgt_embed = nn.Sequential(Embeddings(d_model=512, tgt_vocab), c(position))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7f6a6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder的结构与Encoder类似\n",
    "# 就是6个连续DecoderLayer + 1个LayerNorm\n",
    "# 区别是多了memory -> encoder的输出结果\n",
    "# 以及src_mask和tag_mask\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self, x, memory, src_task, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35adfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8068c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecoderLayer与EncoderLayer大部分类似\n",
    "# 每个sublayer层依然是 norm(x) -> sublayer -> dropout  -> +x [残差]\n",
    "\n",
    "# 不一样的地方\n",
    "# 1. DecoderLayer有3个sublayer, EncoderLayer有2个，多了一个attention\n",
    "# 2. 多出的层为encoder-decoder attention, 即src为query, 它对memory作为key-value的attention\n",
    "#    就是上述self.src_attn(x, m, m, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74a41800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d17add3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "print(src.data)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bd8fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "src_mask = torch.ones(1,1,10)\n",
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b9d3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "ys = torch.zeros(1,1)\n",
    "print(ys.shape)\n",
    "ys = ys.type_as(src)\n",
    "print(ys.shape)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c226833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsequent mask\n",
    "# ensures that predictions for position i can \n",
    "# depend only on the known ouputs at positions less than i\n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1,size,size)\n",
    "    subsequent_task = torch.triu(torch.ones(attn_shape),diagonal=1).type(torch.uint8)\n",
    "    return subsequent_task==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1a272aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ys_size = ys.size(1)\n",
    "print(ys_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "12250d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "attn_shape = (1,ys_size, ys_size)\n",
    "print(attn_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ebb889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_test = torch.ones(attn_shape)\n",
    "subsequent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28499da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_test = torch.triu(subsequent_test, diagonal=1)\n",
    "subsequent_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d436da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0]]], dtype=torch.uint8)\n",
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.triu基本用法\n",
    "# torch.triu(input, diagonal=0):\n",
    "# input: the input tensor\n",
    "# diagonal: the diagonal to consider\n",
    "subsequent_test = subsequent_test.type(torch.uint8)\n",
    "print(subsequent_test)\n",
    "print(subsequent_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "991ecdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_test==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08849abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# decode传入参数:\n",
    "# memory, src_mask, ys, subsequent_mask(ys_size(1))\n",
    "# def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "#       return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "# 就是\n",
    "# self.decoder(tgt_embed(ys), memory, src_mask, subseuent_mask(ys_size(1)))\n",
    "print(ys)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d2b7528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(subsequent_mask(ys.size(1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4c0feb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "print(memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "424fb489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(src_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "14269580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tat_emb和src_emb过程类似\n",
    "# 直接进行shape测试\n",
    "# tgt_vocab=11\n",
    "decoder_position = PositionalEncoding(512,0.1)\n",
    "tgt_emb = nn.Sequential(Embeddings(512,11),decoder_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0645ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "decoder_embedding = tgt_emb(ys)\n",
    "print(decoder_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "635d3614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 忽略掉SublayerConnection的norm步骤\n",
    "# 直接attention\n",
    "decoder_attention = MultiHeadedAttention(h=8,d_model=512,dropout=0.1)\n",
    "x_decoder_attention = decoder_attention(decoder_embedding,decoder_embedding,decoder_embedding,subsequent_mask(ys.size(1)))\n",
    "x_decoder_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "975c182d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再看encoder-decoder attention\n",
    "# 这一步的详细转换再补充\n",
    "# x为[1,1,512], memory [1,10,512] -> output[1,1,512]\n",
    "encoder_decoder_attention = MultiHeadedAttention(h=8,d_model=512,dropout=0.1)\n",
    "x_encoder_decoder_attention = encoder_decoder_attention(x_decoder_attention,memory,memory,src_mask)\n",
    "x_encoder_decoder_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c622dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为inference的ys只有一个元素\n",
    "# 就不再进行SublayerConnection的dropout和残差连接\n",
    "# 可以假设下列代码的输出shape为[1,1,512]\n",
    "#test_model.decode(\n",
    "#            memory, src_mask, ys, subsequent_mask(ys.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "929ed8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "# 再次回到inference_test()\n",
    "out = x_encoder_decoder_attention.type_as(src.data)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d411d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验 prob = test_model.generator(out[:, -1])\n",
    "# generator = Generator(d_model=512, tgt_vocab=11)\n",
    "# standard linear + softmax generation step\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,d_model,vocab):\n",
    "        super(Generator,self).__init__()\n",
    "        self.proj = nn.Linear(d_model,vocab)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return log_softmax(self.proj(x),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a13e7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out[:,-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2fba618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n"
     ]
    }
   ],
   "source": [
    "proj = nn.Linear(512,11)\n",
    "generator_test = proj(out[:,-1].type(torch.float32))\n",
    "print(generator_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d782085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import log_softmax,pad\n",
    "prob = log_softmax(generator_test,dim=-1)\n",
    "print(prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a2361d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3889, -2.3669, -2.4077, -2.3771, -2.4408, -2.3702, -2.4429, -2.3906,\n",
      "         -2.3710, -2.3855, -2.4396]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a265cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([-2.3669], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(prob,dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3165683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "_, next_word = torch.max(prob,dim=1)\n",
    "#print(next_word)\n",
    "next_word = next_word.data[0]\n",
    "print(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "70bc33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n"
     ]
    }
   ],
   "source": [
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e6952a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "ys = torch.cat(\n",
    "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "print(ys) \n",
    "# ye的初始值为tensor([[0]])，再添加最新获得结果tensor(1), 类似一共循环9次\n",
    "# 获得类似tensor([[0, 4, 1, 4, 1, 4, 1, 4, 1, 4]])的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45901152",
   "metadata": {},
   "source": [
    "#### 用inference_test查验结果\n",
    "#### 全部的transformer过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "094c687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "697e8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fe7d91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Untrained Model Prediction: tensor([[ 0,  1,  8,  1,  2,  4, 10, 10, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 1, 4, 1, 4, 1, 4, 1, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 3, 3, 3, 3, 3, 3, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 6, 5, 7, 1, 5, 7, 1, 5, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 1, 3, 9, 9, 9, 9, 9, 9, 9]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 0, 3, 0, 3, 0, 3, 0, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 1, 1, 6, 4, 1, 1, 1, 1, 1]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  1,  4,  8,  9, 10, 10, 10, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[ 0, 10, 10, 10, 10, 10, 10, 10, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "def inference_test():\n",
    "    test_model = make_model(11, 11, 2)\n",
    "    test_model.eval()\n",
    "    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "    src_mask = torch.ones(1, 1, 10)\n",
    "\n",
    "    memory = test_model.encode(src, src_mask)\n",
    "    ys = torch.zeros(1, 1).type_as(src)\n",
    "\n",
    "    for i in range(9):\n",
    "        out = test_model.decode(\n",
    "            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        #print(\"out.shape:\", out.shape)\n",
    "        prob = test_model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "\n",
    "    print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    for _ in range(10):\n",
    "        inference_test()\n",
    "\n",
    "\n",
    "show_example(run_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a30324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
